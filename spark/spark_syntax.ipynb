{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Questions:**\n",
    "- Q1. What is the trend in crime over the past years?\n",
    "- Q2. Which categories of crimes are the most common?\n",
    "- Q3. In whick boroughs is a particular category of crime most prevalent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning Data:**\n",
    "\n",
    "- Filtering the data\n",
    "- Treat with missing values and anomalous data\n",
    "\n",
    "Transforming Data:\n",
    "\n",
    "- Extracting fields\n",
    "- Computing metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imperative programming way: using loops - process each record one by one\n",
    "\n",
    "Functional programming way: apply the same function to each record - allows you  to process data in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Programming\n",
    "\n",
    "- filter: filter records with conditions\n",
    "- map: transform each record to another record\n",
    "- reduce: combined records in a specified way\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import csv\n",
    "from StringIO import StringIO\n",
    "from collections import namedtuple\n",
    "\n",
    "path = \"file///Users...csv\"\n",
    "data = sc.textFile(path)\n",
    "\n",
    "data.take(10)\n",
    "\n",
    "header = data.first()\n",
    "print(header)\n",
    "\n",
    "dataWoHeader = data.filter(lambda x: x <> header)\n",
    "dataWoHeader.first()\n",
    "\n",
    "dataWoHeader.map(lambda x: x.split(\",\")).take(10)\n",
    "\n",
    "fields = header.replace(\" \", \"_\").replace(\"/\", \"_\").split(\",\")\n",
    "print(fields)\n",
    "\n",
    "Crime = namedtuple('Crime', fields, verbose=True)\n",
    "\n",
    "def parse(row):\n",
    "    reader = csv.reader(StringIO(row))\n",
    "    row = reader.next()\n",
    "    return Crime(*row)   \n",
    "    \n",
    "crimes = dataWoHeader.map(parse)\n",
    "crimes.first()\n",
    "crimes.first().Offense\n",
    "\n",
    "crimes.map(lambda x:x.Offence).countByValue()\n",
    "crimes.map(lambda x:x.Occurence_Yeaar).countByValue()\n",
    "crimesFiltered = crimes.filter(lambda x: not (x.Offense == 'NA' or x.Occurrence_Year == ''))\n",
    "                       .filter(lambda x: int(x.Occurrence_Year) >= 2006)\n",
    "                    \n",
    "crimesFiltered.map(lambda x:x.Occurence_Yeaar).countByValue()    \n",
    "\n",
    "def extractCoords(location):\n",
    "    location_lat = float(location[1:location.index(\",\")])\n",
    "    location_lon = float(location[location.index(\",\")+1:-1])\n",
    "    return (location_lat, location_lon)\n",
    "    \n",
    "crimesFiltered.map(lambda x: extractCoords(x.Location_1)).reduce(lambda:x,y:(min(x[0],y[0]), min(x[1], y[1])))    \n",
    "\n",
    "\n",
    "crimesFiltered.filter(lambda x:x.Offense=='BURGLARY').map(lambda x:x.Occurence_Yeaar).countByValue()    \n",
    "\n",
    "import gmplot\n",
    "gmap = gmplot.GoogleMapPlotter(37.428, -122.145, 16).from_geocode(\"New York City\")\n",
    "\n",
    "b_lats = crimesFiltered.map(lambda x: extractCoords(x.Location_1))[0].collect()\n",
    "b_lons = crimesFiltered.map(lambda x: extractCoords(x.Location_1))[1].collect()\n",
    "\n",
    "gmap.scatter(b_lats, b_lons, '#DE1515', size=40, marker=False)\n",
    "gmap.draw(\"mymap.html\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- collect()\n",
    "- take()\n",
    "- first()\n",
    "\n",
    "- countByValue()\n",
    "- join()\n",
    "\n",
    "Two types of RDD:\n",
    "- Base RDD\n",
    "- Pair RDD - each record is a tuple  (word, count)\n",
    "    - Summarize by keys:\n",
    "        - reduceByKey(): sum, max, min (mean will not work)\n",
    "            - like reduce, is a function takes 2 arguments\n",
    "            - only combines values with the same key (reduce applys to the complete records)\n",
    "            - is a transformation (reduce is an action)\n",
    "        - combineByKey(): mean (see below)\n",
    "    - Merge by keys:\n",
    "        - join\n",
    "        - leftOuterJoin\n",
    "        - rightOuterJoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Data Along Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from datetime import datetime\n",
    "def parseTraffic(row):\n",
    "    DATE_FMT = \"%m/%d/%Y %H:%M\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0], DATE_FMT)\n",
    "    row[1] = int(row[1])\n",
    "    return (row[0], row[1])\n",
    "    \n",
    "def parseGames(row):\n",
    "    DATE_FMT = \"%m/%d/%Y\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0], DATE_FMT).date()\n",
    "    return (row[0], row[4])    \n",
    "    \n",
    "trafficParsed = traffic.map(parseTraffic)    \n",
    "gamesParsed = games.map(parseHames)\n",
    "\n",
    "dailyTrend = trafficParsed.map(lambda x: (x[0].date(), x[1])).reduceByKey(lambda x, y: x + y)\n",
    "dailyTrend.sortBy(lambda x: -x[-1]).take(10)  #sort in descending order\n",
    "\n",
    "## Merging Pair RDDs\n",
    "\n",
    "dailyTrendCombined = dailyTrend.leftOuterJoin(gamesParsed)\n",
    "dailyTrendCombined.take(10)\n",
    "\n",
    "def checkGameDay(row):\n",
    "    if row[1][1] == None:\n",
    "        return (row[0], row[1][1], \"Regular Day\", row[1][0])\n",
    "    else:\n",
    "        return (row[0], row[1][1], \"Game Day\", row[1][0])\n",
    "\n",
    "dailyTrendbyGames = dailyTrendCombined.map(checkGameDay)\n",
    "dailyTrendbyGames.take(10)\n",
    "\n",
    "dailyTrendbyGames.sortBy(lambda x:-x[3]).take(10)\n",
    "\n",
    "# average traffic on game day vs non game day\n",
    "dailyTrendbyGames.map(lambda x: (x[2], x[3])).combineByKey(lambda value: (value,1), \\\n",
    "                                      lambda acc, value:(acc[0]+value, acc[1] + 1), \\\n",
    "                                      lambda acc1, acc2:(acc1[0]+acc2[0], acc1[1]+acc2[1])) \\\n",
    "                                      .mapValues(lambda x:x[0] / x[1]).collect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Marvel Social Universe](http:/bioinfo.uib.es/~joemiro/marvel.html)\n",
    "\n",
    "**Network:**\n",
    "- vertex: the characters\n",
    "- edges: relationship between the characters\n",
    "\n",
    "**Similar networks:**\n",
    "- webpages\n",
    "- members of a social network\n",
    "- Articles/Documents/Text\n",
    "\n",
    "**Questions:**\n",
    "- Q1. Find the most influential charcacters\n",
    "- Q2. Build a co-occurence network from the given data\n",
    "- Q3. Find the most important cliques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "booksPath = \"file:///User.../Books.txt\"\n",
    "charactersPath = \"file:///User.../Characters.txt\"\n",
    "edgesPath = \"file:///Users.../Edges.txt\"\n",
    "\n",
    "books = sc.textFile(booksPath)            # contains vertex name and book name\n",
    "characters = sc.textFile(charactersPath)  # contains vertex name and character name\n",
    "edges = sc.textFile(edgesPath)            # contains complete list of vertices and a list of edge contains character and list of books\n",
    "\n",
    "# filter out vertics \n",
    "def edgeFilter(row):\n",
    "    if '*' in row or '\"' in row:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "edgesFiltered = edges.filter(edgeFilter)\n",
    "\n",
    "characterBookMap = edgesFiltered.map(lambda x: x.split()).map(lambda x: (x[0], x[1:]))\n",
    "\n",
    "def charParse(row):\n",
    "    row = row.split(\":\")\n",
    "    return (row[0][7:], row[1].strip())\n",
    "    \n",
    "characterLookup = characters.map(charParse).collectAsMap()    # collectAsMap() return data as a dictionary\n",
    "\n",
    "characterStrength = characterBookMap.mapValues(lambda x:len(x)).map(lambda x: (characterLoopup[x[0]], x[1])) \\\n",
    "                                    .reduceByKey(lambda x,y: x + y) \\\n",
    "                                    .sortBy(lambda x: -x[1])\n",
    "characterStrength.take[10]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurence Network\n",
    "\n",
    "Two entities occur together in some way - product recommendation\n",
    "\n",
    "Step 1:  CharacterBookMap (character, list of books)  --> bookCharacterMap (book, list of characters)\n",
    "Step 2:  bookCharacterMap (book, list of characters)  --> pairs of characters (have duplicates)\n",
    "Step 3:  pairs of characters  -->  (pair of character, #count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "bookCharacterMap = characterBookMap.flatMapValue(lambda x: x).map(lambda x: (x[1], x[0])) \\\n",
    "                                   .reduceByKey(lambda x,y: x + \",' +y\") \\\n",
    "                                   .mapValues(lambda x: x.split(\",\"))\n",
    "import itertools\n",
    "cooccurenceMap = bookCharacterMap.flatMap(lambda x: list(itertools.combinations(x[1], 2)))\n",
    "cooccurenceStrength = cooccurenceMap.map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "cooccurenceStrength.take(10)\n",
    "\n",
    "sortedCooccurence = coocurenceEdges.sortBy(lambda x:-x[2]).map(lambda x: (characterLookup[x[0]], characterLookup[x[1]],x[2]))\n",
    "sortedCooccurence.filter(lambda x:'SPIDER-MAN/PETER PARKER' in x).take(10)\n",
    "\n",
    "sortedCooccurence.map(lambda x:x[2]).states()\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "edges = sortedCooccurence.map(lambda x: (x[0],x[1],{'weight':1000/x[2]})).take(50)\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G))\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
