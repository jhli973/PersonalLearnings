{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from LoadSplitData import Process\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape (24076, 80, 80, 3), label shape (24076,), ratio of authorized data 0.4503655092208008\n",
      "X_train shape: (12639, 80, 80, 3)\n",
      "12639 train samples\n",
      "5418 valid samples\n",
      "6019 test samples\n"
     ]
    }
   ],
   "source": [
    "data = Process()\n",
    "data.split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from TuneModel import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 80, 80, 32)    896         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 80, 80, 32)    9248        convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 40, 40, 32)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 40, 40, 32)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 40, 40, 64)    18496       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 40, 40, 64)    36928       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 20, 20, 64)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 20, 20, 64)    0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 20, 20, 96)    55392       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 20, 20, 96)    83040       convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 10, 10, 96)    0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 10, 10, 96)    0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 9600)          0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 960)           9216960     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 960)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 960)           0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             1922        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 2)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 117s - loss: 0.2043 - acc: 0.9165 - fbeta_score: 0.9165 - precision: 0.9165 - val_loss: 0.0660 - val_acc: 0.9767 - val_fbeta_score: 0.9767 - val_precision: 0.9767\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.0812 - acc: 0.9737 - fbeta_score: 0.9737 - precision: 0.9737 - val_loss: 0.0407 - val_acc: 0.9856 - val_fbeta_score: 0.9856 - val_precision: 0.9856\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.0612 - acc: 0.9789 - fbeta_score: 0.9789 - precision: 0.9789 - val_loss: 0.0305 - val_acc: 0.9874 - val_fbeta_score: 0.9874 - val_precision: 0.9874\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.0471 - acc: 0.9832 - fbeta_score: 0.9832 - precision: 0.9832 - val_loss: 0.0288 - val_acc: 0.9900 - val_fbeta_score: 0.9900 - val_precision: 0.9900\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.0388 - acc: 0.9868 - fbeta_score: 0.9868 - precision: 0.9868 - val_loss: 0.0250 - val_acc: 0.9911 - val_fbeta_score: 0.9911 - val_precision: 0.9911\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.0290 - acc: 0.9903 - fbeta_score: 0.9903 - precision: 0.9903 - val_loss: 0.0188 - val_acc: 0.9935 - val_fbeta_score: 0.9935 - val_precision: 0.9935\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.0274 - acc: 0.9900 - fbeta_score: 0.9900 - precision: 0.9900 - val_loss: 0.0124 - val_acc: 0.9967 - val_fbeta_score: 0.9967 - val_precision: 0.9967\n",
      "Epoch 8/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.0212 - acc: 0.9934 - fbeta_score: 0.9934 - precision: 0.9934 - val_loss: 0.0094 - val_acc: 0.9970 - val_fbeta_score: 0.9970 - val_precision: 0.9970\n",
      "Epoch 9/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.0213 - acc: 0.9937 - fbeta_score: 0.9937 - precision: 0.9937 - val_loss: 0.0113 - val_acc: 0.9961 - val_fbeta_score: 0.9961 - val_precision: 0.9961\n",
      "Model Saved.\n",
      "Metric: adam, batch_size: 40, evaluate value: 99.65110453364659\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 80, 80, 32)    896         convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 80, 80, 32)    9248        convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 40, 40, 32)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 40, 40, 32)    0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 40, 40, 64)    18496       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 20, 20, 64)    0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 20, 20, 64)    0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 20, 20, 96)    55392       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 10, 10, 96)    0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 10, 10, 96)    0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 9600)          0           dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 960)           9216960     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 960)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 960)           0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             1922        dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 103s - loss: 0.2220 - acc: 0.9082 - fbeta_score: 0.9082 - precision: 0.9082 - val_loss: 0.0621 - val_acc: 0.9788 - val_fbeta_score: 0.9788 - val_precision: 0.9788\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.0865 - acc: 0.9710 - fbeta_score: 0.9710 - precision: 0.9710 - val_loss: 0.0406 - val_acc: 0.9847 - val_fbeta_score: 0.9847 - val_precision: 0.9847\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.0563 - acc: 0.9805 - fbeta_score: 0.9805 - precision: 0.9805 - val_loss: 0.0330 - val_acc: 0.9878 - val_fbeta_score: 0.9878 - val_precision: 0.9878\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 101s - loss: 0.0439 - acc: 0.9847 - fbeta_score: 0.9847 - precision: 0.9847 - val_loss: 0.0234 - val_acc: 0.9926 - val_fbeta_score: 0.9926 - val_precision: 0.9926\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.0332 - acc: 0.9889 - fbeta_score: 0.9889 - precision: 0.9889 - val_loss: 0.0178 - val_acc: 0.9941 - val_fbeta_score: 0.9941 - val_precision: 0.9941\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.0286 - acc: 0.9907 - fbeta_score: 0.9907 - precision: 0.9907 - val_loss: 0.0116 - val_acc: 0.9959 - val_fbeta_score: 0.9959 - val_precision: 0.9959\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.0237 - acc: 0.9920 - fbeta_score: 0.9920 - precision: 0.9920 - val_loss: 0.0130 - val_acc: 0.9946 - val_fbeta_score: 0.9946 - val_precision: 0.9946\n",
      "Model Saved.\n",
      "Metric: adam, batch_size: 50, evaluate value: 99.63449078117975\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_13 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 40, 40, 32)    0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 40, 40, 32)    0           maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 40, 40, 64)    18496       dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 20, 20, 64)    0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 20, 20, 96)    55392       dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 10, 10, 96)    0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 9600)          0           dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 960)           9216960     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 960)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 960)           0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2)             1922        dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 2)             0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.2089 - acc: 0.9092 - fbeta_score: 0.9092 - precision: 0.9092 - val_loss: 0.0702 - val_acc: 0.9743 - val_fbeta_score: 0.9743 - val_precision: 0.9743\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0802 - acc: 0.9722 - fbeta_score: 0.9722 - precision: 0.9722 - val_loss: 0.0366 - val_acc: 0.9874 - val_fbeta_score: 0.9874 - val_precision: 0.9874\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0491 - acc: 0.9835 - fbeta_score: 0.9835 - precision: 0.9835 - val_loss: 0.0238 - val_acc: 0.9926 - val_fbeta_score: 0.9926 - val_precision: 0.9926\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0389 - acc: 0.9868 - fbeta_score: 0.9868 - precision: 0.9868 - val_loss: 0.0169 - val_acc: 0.9945 - val_fbeta_score: 0.9945 - val_precision: 0.9945\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0298 - acc: 0.9892 - fbeta_score: 0.9892 - precision: 0.9892 - val_loss: 0.0133 - val_acc: 0.9958 - val_fbeta_score: 0.9958 - val_precision: 0.9958\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 98s - loss: 0.0281 - acc: 0.9903 - fbeta_score: 0.9903 - precision: 0.9903 - val_loss: 0.0210 - val_acc: 0.9928 - val_fbeta_score: 0.9928 - val_precision: 0.9928\n",
      "Model Saved.\n",
      "Metric: adam, batch_size: 60, evaluate value: 99.3686672658456\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_19 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 40, 40, 64)    18496       dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_11 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 20, 20, 96)    55392       dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_12 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 9600)          0           dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 960)           9216960     flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 960)           0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 960)           0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 2)             1922        dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 2)             0           dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 98s - loss: 0.2157 - acc: 0.9066 - fbeta_score: 0.9066 - precision: 0.9066 - val_loss: 0.0695 - val_acc: 0.9751 - val_fbeta_score: 0.9751 - val_precision: 0.9751\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0779 - acc: 0.9730 - fbeta_score: 0.9730 - precision: 0.9730 - val_loss: 0.0368 - val_acc: 0.9867 - val_fbeta_score: 0.9867 - val_precision: 0.9867\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0536 - acc: 0.9820 - fbeta_score: 0.9820 - precision: 0.9820 - val_loss: 0.0331 - val_acc: 0.9900 - val_fbeta_score: 0.9900 - val_precision: 0.9900\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0414 - acc: 0.9859 - fbeta_score: 0.9859 - precision: 0.9859 - val_loss: 0.0171 - val_acc: 0.9943 - val_fbeta_score: 0.9943 - val_precision: 0.9943\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0331 - acc: 0.9884 - fbeta_score: 0.9884 - precision: 0.9884 - val_loss: 0.0142 - val_acc: 0.9958 - val_fbeta_score: 0.9958 - val_precision: 0.9958\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0237 - acc: 0.9920 - fbeta_score: 0.9920 - precision: 0.9920 - val_loss: 0.0103 - val_acc: 0.9972 - val_fbeta_score: 0.9972 - val_precision: 0.9972\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0247 - acc: 0.9925 - fbeta_score: 0.9925 - precision: 0.9925 - val_loss: 0.0233 - val_acc: 0.9922 - val_fbeta_score: 0.9922 - val_precision: 0.9922\n",
      "Model Saved.\n",
      "Metric: adam, batch_size: 70, evaluate value: 99.25236772670958\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_25 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_13 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_13[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_27 (Convolution2D) (None, 40, 40, 64)    18496       dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_28 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_14 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_14[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_29 (Convolution2D) (None, 20, 20, 96)    55392       dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_30 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_15 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_15[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 9600)          0           dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 960)           9216960     flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 960)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 960)           0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 2)             1922        dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 2)             0           dense_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.2600 - acc: 0.8748 - fbeta_score: 0.8748 - precision: 0.8748 - val_loss: 0.0741 - val_acc: 0.9738 - val_fbeta_score: 0.9738 - val_precision: 0.9738\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.0809 - acc: 0.9727 - fbeta_score: 0.9727 - precision: 0.9727 - val_loss: 0.0335 - val_acc: 0.9860 - val_fbeta_score: 0.9860 - val_precision: 0.9860\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0629 - acc: 0.9782 - fbeta_score: 0.9782 - precision: 0.9782 - val_loss: 0.0221 - val_acc: 0.9934 - val_fbeta_score: 0.9934 - val_precision: 0.9934\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.0421 - acc: 0.9859 - fbeta_score: 0.9859 - precision: 0.9859 - val_loss: 0.0198 - val_acc: 0.9921 - val_fbeta_score: 0.9921 - val_precision: 0.9921\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.0414 - acc: 0.9843 - fbeta_score: 0.9843 - precision: 0.9843 - val_loss: 0.0344 - val_acc: 0.9858 - val_fbeta_score: 0.9858 - val_precision: 0.9858\n",
      "Model Saved.\n",
      "Metric: adam, batch_size: 80, evaluate value: 99.00315603676736\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_31 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_32 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_16 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_16[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_33 (Convolution2D) (None, 40, 40, 64)    18496       dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_34 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_17 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_17[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_35 (Convolution2D) (None, 20, 20, 96)    55392       dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_36 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_18 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_18[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 9600)          0           dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 960)           9216960     flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 960)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 960)           0           activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 2)             1922        dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 2)             0           dense_12[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 96s - loss: 0.2780 - acc: 0.8717 - fbeta_score: 0.8717 - precision: 0.8717 - val_loss: 0.0707 - val_acc: 0.9731 - val_fbeta_score: 0.9731 - val_precision: 0.9731\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0872 - acc: 0.9691 - fbeta_score: 0.9691 - precision: 0.9691 - val_loss: 0.0466 - val_acc: 0.9838 - val_fbeta_score: 0.9838 - val_precision: 0.9838\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 92s - loss: 0.0709 - acc: 0.9757 - fbeta_score: 0.9757 - precision: 0.9757 - val_loss: 0.0341 - val_acc: 0.9893 - val_fbeta_score: 0.9893 - val_precision: 0.9893\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0499 - acc: 0.9825 - fbeta_score: 0.9825 - precision: 0.9825 - val_loss: 0.0250 - val_acc: 0.9904 - val_fbeta_score: 0.9904 - val_precision: 0.9904\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0391 - acc: 0.9862 - fbeta_score: 0.9862 - precision: 0.9862 - val_loss: 0.0173 - val_acc: 0.9950 - val_fbeta_score: 0.9950 - val_precision: 0.9950\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0288 - acc: 0.9908 - fbeta_score: 0.9908 - precision: 0.9908 - val_loss: 0.0171 - val_acc: 0.9934 - val_fbeta_score: 0.9934 - val_precision: 0.9934\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0260 - acc: 0.9919 - fbeta_score: 0.9919 - precision: 0.9919 - val_loss: 0.0165 - val_acc: 0.9928 - val_fbeta_score: 0.9928 - val_precision: 0.9928\n",
      "Epoch 8/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0247 - acc: 0.9917 - fbeta_score: 0.9917 - precision: 0.9917 - val_loss: 0.0091 - val_acc: 0.9976 - val_fbeta_score: 0.9976 - val_precision: 0.9976\n",
      "Epoch 9/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0197 - acc: 0.9932 - fbeta_score: 0.9932 - precision: 0.9932 - val_loss: 0.0097 - val_acc: 0.9959 - val_fbeta_score: 0.9959 - val_precision: 0.9959\n",
      "Model Saved.\n",
      "Metric: adam, batch_size: 90, evaluate value: 99.7507901262219\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_37 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_38 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_19 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_19[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_39 (Convolution2D) (None, 40, 40, 64)    18496       dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_40 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_20 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_40[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_20[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_41 (Convolution2D) (None, 20, 20, 96)    55392       dropout_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_42 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_41[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_21 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_42[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_21[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 9600)          0           dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 960)           9216960     flatten_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 960)           0           dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)             (None, 960)           0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 2)             1922        dropout_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 2)             0           dense_14[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.4574 - acc: 0.7783 - fbeta_score: 0.7783 - precision: 0.7783 - val_loss: 0.3657 - val_acc: 0.8405 - val_fbeta_score: 0.8405 - val_precision: 0.8405\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.3405 - acc: 0.8518 - fbeta_score: 0.8518 - precision: 0.8518 - val_loss: 0.2889 - val_acc: 0.8813 - val_fbeta_score: 0.8813 - val_precision: 0.8813\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.2641 - acc: 0.8897 - fbeta_score: 0.8897 - precision: 0.8897 - val_loss: 0.1896 - val_acc: 0.9324 - val_fbeta_score: 0.9324 - val_precision: 0.9324\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.1851 - acc: 0.9260 - fbeta_score: 0.9260 - precision: 0.9260 - val_loss: 0.1274 - val_acc: 0.9622 - val_fbeta_score: 0.9622 - val_precision: 0.9622\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.1279 - acc: 0.9524 - fbeta_score: 0.9524 - precision: 0.9524 - val_loss: 0.0905 - val_acc: 0.9653 - val_fbeta_score: 0.9653 - val_precision: 0.9653\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.1020 - acc: 0.9619 - fbeta_score: 0.9619 - precision: 0.9619 - val_loss: 0.0745 - val_acc: 0.9708 - val_fbeta_score: 0.9708 - val_precision: 0.9708\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0867 - acc: 0.9672 - fbeta_score: 0.9672 - precision: 0.9672 - val_loss: 0.0590 - val_acc: 0.9769 - val_fbeta_score: 0.9769 - val_precision: 0.9769\n",
      "Epoch 8/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0723 - acc: 0.9723 - fbeta_score: 0.9723 - precision: 0.9723 - val_loss: 0.0390 - val_acc: 0.9873 - val_fbeta_score: 0.9873 - val_precision: 0.9873\n",
      "Epoch 9/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0652 - acc: 0.9754 - fbeta_score: 0.9754 - precision: 0.9754 - val_loss: 0.0365 - val_acc: 0.9869 - val_fbeta_score: 0.9869 - val_precision: 0.9869\n",
      "Epoch 10/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0602 - acc: 0.9769 - fbeta_score: 0.9769 - precision: 0.9769 - val_loss: 0.0348 - val_acc: 0.9887 - val_fbeta_score: 0.9887 - val_precision: 0.9887\n",
      "Epoch 11/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0558 - acc: 0.9796 - fbeta_score: 0.9796 - precision: 0.9796 - val_loss: 0.0243 - val_acc: 0.9913 - val_fbeta_score: 0.9913 - val_precision: 0.9913\n",
      "Epoch 12/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0518 - acc: 0.9818 - fbeta_score: 0.9818 - precision: 0.9818 - val_loss: 0.0224 - val_acc: 0.9937 - val_fbeta_score: 0.9937 - val_precision: 0.9937\n",
      "Epoch 13/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0452 - acc: 0.9843 - fbeta_score: 0.9843 - precision: 0.9843 - val_loss: 0.0332 - val_acc: 0.9880 - val_fbeta_score: 0.9880 - val_precision: 0.9880\n",
      "Model Saved.\n",
      "Metric: sgd, batch_size: 40, evaluate value: 98.50473412546056\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_43 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_44 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_43[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_22 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_44[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_22[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_45 (Convolution2D) (None, 40, 40, 64)    18496       dropout_29[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_46 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_23 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_47 (Convolution2D) (None, 20, 20, 96)    55392       dropout_30[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_48 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_47[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_24 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_48[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_24[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 9600)          0           dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 960)           9216960     flatten_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 960)           0           dense_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 960)           0           activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 2)             1922        dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 2)             0           dense_16[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.4903 - acc: 0.7630 - fbeta_score: 0.7630 - precision: 0.7630 - val_loss: 0.3728 - val_acc: 0.8429 - val_fbeta_score: 0.8429 - val_precision: 0.8429\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.3458 - acc: 0.8513 - fbeta_score: 0.8513 - precision: 0.8513 - val_loss: 0.3423 - val_acc: 0.8536 - val_fbeta_score: 0.8536 - val_precision: 0.8536\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.2752 - acc: 0.8859 - fbeta_score: 0.8859 - precision: 0.8859 - val_loss: 0.2128 - val_acc: 0.9179 - val_fbeta_score: 0.9179 - val_precision: 0.9179\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.2054 - acc: 0.9191 - fbeta_score: 0.9191 - precision: 0.9191 - val_loss: 0.1412 - val_acc: 0.9542 - val_fbeta_score: 0.9542 - val_precision: 0.9542\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.1474 - acc: 0.9455 - fbeta_score: 0.9455 - precision: 0.9455 - val_loss: 0.1018 - val_acc: 0.9664 - val_fbeta_score: 0.9664 - val_precision: 0.9664\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.1185 - acc: 0.9548 - fbeta_score: 0.9548 - precision: 0.9548 - val_loss: 0.0771 - val_acc: 0.9714 - val_fbeta_score: 0.9714 - val_precision: 0.9714\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.1003 - acc: 0.9624 - fbeta_score: 0.9624 - precision: 0.9624 - val_loss: 0.0712 - val_acc: 0.9738 - val_fbeta_score: 0.9738 - val_precision: 0.9738\n",
      "Epoch 8/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0870 - acc: 0.9687 - fbeta_score: 0.9687 - precision: 0.9687 - val_loss: 0.0538 - val_acc: 0.9843 - val_fbeta_score: 0.9843 - val_precision: 0.9843\n",
      "Epoch 9/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0774 - acc: 0.9716 - fbeta_score: 0.9716 - precision: 0.9716 - val_loss: 0.0440 - val_acc: 0.9858 - val_fbeta_score: 0.9858 - val_precision: 0.9858\n",
      "Epoch 10/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0669 - acc: 0.9756 - fbeta_score: 0.9756 - precision: 0.9756 - val_loss: 0.0698 - val_acc: 0.9719 - val_fbeta_score: 0.9719 - val_precision: 0.9719\n",
      "Model Saved.\n",
      "Metric: sgd, batch_size: 50, evaluate value: 97.20883850818419\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_49 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_50 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_49[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_25 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_50[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_25[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_51 (Convolution2D) (None, 40, 40, 64)    18496       dropout_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_52 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_51[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_26 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_52[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_26[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_53 (Convolution2D) (None, 20, 20, 96)    55392       dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_54 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_53[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_27 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_54[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_27[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 9600)          0           dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 960)           9216960     flatten_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 960)           0           dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 960)           0           activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 2)             1922        dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 2)             0           dense_18[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.5034 - acc: 0.7515 - fbeta_score: 0.7515 - precision: 0.7515 - val_loss: 0.3715 - val_acc: 0.8466 - val_fbeta_score: 0.8466 - val_precision: 0.8466\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.3463 - acc: 0.8535 - fbeta_score: 0.8535 - precision: 0.8535 - val_loss: 0.3737 - val_acc: 0.8346 - val_fbeta_score: 0.8346 - val_precision: 0.8346\n",
      "Model Saved.\n",
      "Metric: sgd, batch_size: 60, evaluate value: 83.30287944242633\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_55 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_56 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_55[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_28 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_56[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_28[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_57 (Convolution2D) (None, 40, 40, 64)    18496       dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_58 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_57[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_29 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_58[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_29[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_59 (Convolution2D) (None, 20, 20, 96)    55392       dropout_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_60 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_59[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_30 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_60[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_30[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 9600)          0           dropout_39[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 960)           9216960     flatten_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 960)           0           dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)             (None, 960)           0           activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 2)             1922        dropout_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 2)             0           dense_20[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.5075 - acc: 0.7475 - fbeta_score: 0.7475 - precision: 0.7475 - val_loss: 0.4078 - val_acc: 0.8300 - val_fbeta_score: 0.8300 - val_precision: 0.8300\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.3616 - acc: 0.8429 - fbeta_score: 0.8429 - precision: 0.8429 - val_loss: 0.3393 - val_acc: 0.8634 - val_fbeta_score: 0.8634 - val_precision: 0.8634\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.3126 - acc: 0.8657 - fbeta_score: 0.8657 - precision: 0.8657 - val_loss: 0.3185 - val_acc: 0.8651 - val_fbeta_score: 0.8651 - val_precision: 0.8651\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.2611 - acc: 0.8915 - fbeta_score: 0.8915 - precision: 0.8915 - val_loss: 0.2182 - val_acc: 0.9254 - val_fbeta_score: 0.9254 - val_precision: 0.9254\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.2094 - acc: 0.9180 - fbeta_score: 0.9180 - precision: 0.9180 - val_loss: 0.1896 - val_acc: 0.9293 - val_fbeta_score: 0.9293 - val_precision: 0.9293\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.1608 - acc: 0.9380 - fbeta_score: 0.9380 - precision: 0.9380 - val_loss: 0.1295 - val_acc: 0.9524 - val_fbeta_score: 0.9524 - val_precision: 0.9524\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.1392 - acc: 0.9464 - fbeta_score: 0.9464 - precision: 0.9464 - val_loss: 0.0956 - val_acc: 0.9677 - val_fbeta_score: 0.9677 - val_precision: 0.9677\n",
      "Epoch 8/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.1235 - acc: 0.9517 - fbeta_score: 0.9517 - precision: 0.9517 - val_loss: 0.0928 - val_acc: 0.9675 - val_fbeta_score: 0.9675 - val_precision: 0.9675\n",
      "Epoch 9/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.1090 - acc: 0.9581 - fbeta_score: 0.9581 - precision: 0.9581 - val_loss: 0.0720 - val_acc: 0.9738 - val_fbeta_score: 0.9738 - val_precision: 0.9738\n",
      "Epoch 10/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.0961 - acc: 0.9642 - fbeta_score: 0.9642 - precision: 0.9642 - val_loss: 0.0723 - val_acc: 0.9727 - val_fbeta_score: 0.9727 - val_precision: 0.9727\n",
      "Model Saved.\n",
      "Metric: sgd, batch_size: 70, evaluate value: 97.3251382364627\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_61 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_62 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_61[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_31 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_62[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_31[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_63 (Convolution2D) (None, 40, 40, 64)    18496       dropout_41[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_64 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_63[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_32 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_64[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_32[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_65 (Convolution2D) (None, 20, 20, 96)    55392       dropout_42[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_66 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_65[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_33 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_66[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_33[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 9600)          0           dropout_43[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 960)           9216960     flatten_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 960)           0           dense_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)             (None, 960)           0           activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 2)             1922        dropout_44[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 2)             0           dense_22[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.5584 - acc: 0.7099 - fbeta_score: 0.7099 - precision: 0.7099 - val_loss: 0.4094 - val_acc: 0.8304 - val_fbeta_score: 0.8304 - val_precision: 0.8304\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.3820 - acc: 0.8317 - fbeta_score: 0.8317 - precision: 0.8317 - val_loss: 0.3633 - val_acc: 0.8453 - val_fbeta_score: 0.8453 - val_precision: 0.8453\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.3361 - acc: 0.8560 - fbeta_score: 0.8560 - precision: 0.8560 - val_loss: 0.3224 - val_acc: 0.8629 - val_fbeta_score: 0.8629 - val_precision: 0.8629\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.2932 - acc: 0.8788 - fbeta_score: 0.8788 - precision: 0.8788 - val_loss: 0.2662 - val_acc: 0.8985 - val_fbeta_score: 0.8985 - val_precision: 0.8985\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.2374 - acc: 0.9016 - fbeta_score: 0.9016 - precision: 0.9016 - val_loss: 0.2064 - val_acc: 0.9232 - val_fbeta_score: 0.9232 - val_precision: 0.9232\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.1923 - acc: 0.9214 - fbeta_score: 0.9214 - precision: 0.9214 - val_loss: 0.1419 - val_acc: 0.9551 - val_fbeta_score: 0.9551 - val_precision: 0.9551\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.1582 - acc: 0.9386 - fbeta_score: 0.9386 - precision: 0.9386 - val_loss: 0.1910 - val_acc: 0.9232 - val_fbeta_score: 0.9232 - val_precision: 0.9232\n",
      "Model Saved.\n",
      "Metric: sgd, batch_size: 80, evaluate value: 92.20800937598558\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_67 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_68 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_67[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_34 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_68[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_34[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_69 (Convolution2D) (None, 40, 40, 64)    18496       dropout_45[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_70 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_69[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_35 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_70[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_35[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_71 (Convolution2D) (None, 20, 20, 96)    55392       dropout_46[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_72 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_71[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_36 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_72[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_36[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 9600)          0           dropout_47[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 960)           9216960     flatten_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 960)           0           dense_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)             (None, 960)           0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 2)             1922        dropout_48[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 2)             0           dense_24[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.5695 - acc: 0.6884 - fbeta_score: 0.6884 - precision: 0.6884 - val_loss: 0.4626 - val_acc: 0.7935 - val_fbeta_score: 0.7935 - val_precision: 0.7935\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.3880 - acc: 0.8292 - fbeta_score: 0.8292 - precision: 0.8292 - val_loss: 0.3646 - val_acc: 0.8498 - val_fbeta_score: 0.8498 - val_precision: 0.8498\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.3462 - acc: 0.8512 - fbeta_score: 0.8512 - precision: 0.8512 - val_loss: 0.3127 - val_acc: 0.8739 - val_fbeta_score: 0.8739 - val_precision: 0.8739\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.3027 - acc: 0.8751 - fbeta_score: 0.8751 - precision: 0.8751 - val_loss: 0.2544 - val_acc: 0.8963 - val_fbeta_score: 0.8963 - val_precision: 0.8963\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.2612 - acc: 0.8941 - fbeta_score: 0.8941 - precision: 0.8941 - val_loss: 0.2304 - val_acc: 0.9123 - val_fbeta_score: 0.9123 - val_precision: 0.9123\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.2190 - acc: 0.9114 - fbeta_score: 0.9114 - precision: 0.9114 - val_loss: 0.1684 - val_acc: 0.9413 - val_fbeta_score: 0.9413 - val_precision: 0.9413\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.1772 - acc: 0.9290 - fbeta_score: 0.9290 - precision: 0.9290 - val_loss: 0.1403 - val_acc: 0.9494 - val_fbeta_score: 0.9494 - val_precision: 0.9494\n",
      "Epoch 8/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.1390 - acc: 0.9482 - fbeta_score: 0.9482 - precision: 0.9482 - val_loss: 0.0961 - val_acc: 0.9694 - val_fbeta_score: 0.9694 - val_precision: 0.9694\n",
      "Epoch 9/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.1235 - acc: 0.9555 - fbeta_score: 0.9555 - precision: 0.9555 - val_loss: 0.0992 - val_acc: 0.9616 - val_fbeta_score: 0.9616 - val_precision: 0.9616\n",
      "Model Saved.\n",
      "Metric: sgd, batch_size: 90, evaluate value: 96.1455424831325\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = r'C:\\Users\\dbsnail\\ImageProject\\models\\tune_ml' #_sgd.h5'\n",
    "\n",
    "batch_sizes = [40, 50, 60, 70, 80 ,90]\n",
    "optimizers = ['adam', 'sgd']\n",
    "model_dict = {}\n",
    "for optimizer in optimizers:\n",
    "    for batch_size in batch_sizes:\n",
    "\n",
    "        file_path = FILE_PATH + '_' + str(batch_size) + '_' + optimizer + '_' + 'adam.h5'\n",
    "        model = Model(batch_size)\n",
    "        model.build_model(data)\n",
    "        model.train(data, optimizer)\n",
    "        model.save(file_path)\n",
    "        acc = model.evaluate(data)\n",
    "        print(\"Metric: {}, batch_size: {}, evaluate value: {}\".format(optimizer, batch_size, acc))\n",
    "        batch_size_acc = (batch_size, acc) \n",
    "        if optimizer in model_dict.keys():\n",
    "            model_dict[optimizer].append(batch_size_acc)\n",
    "        else:\n",
    "            model_dict[optimizer] = [batch_size_acc]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adam</th>\n",
       "      <th>sgd</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.651105</td>\n",
       "      <td>98.504734</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.634491</td>\n",
       "      <td>97.208839</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.368667</td>\n",
       "      <td>83.302879</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.252368</td>\n",
       "      <td>97.325138</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.003156</td>\n",
       "      <td>92.208009</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.750790</td>\n",
       "      <td>96.145542</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        adam        sgd  batch_size\n",
       "0  99.651105  98.504734          40\n",
       "1  99.634491  97.208839          50\n",
       "2  99.368667  83.302879          60\n",
       "3  99.252368  97.325138          70\n",
       "4  99.003156  92.208009          80\n",
       "5  99.750790  96.145542          90"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open('model_matric.txt', 'w') as outfile:\n",
    "    json.dumps(model_dict, outfile) \n",
    "model_acc = pd.DataFrame(model_dict)\n",
    "model_acc['batch_size'] = model_acc.adam.map(lambda x: x[0])\n",
    "model_acc['adam'] = model_acc.adam.map(lambda x: x[1])\n",
    "model_acc['sgd'] = model_acc.sgd.map(lambda x: x[1])\n",
    "model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGHCAYAAABrpPKuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGAfqPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b91f84a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(model_acc.batch_size, model_acc.adam, '-o', label = 'adam')\n",
    "plt.title(\"Summary of Test Data Prediction Result\")\n",
    "plt.ylabel(\"Prediction Accuracy\")\n",
    "plt.legend(loc=3)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(model_acc.batch_size, model_acc.sgd, '--r', label = 'sgd')\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Prediction fbeta score\")\n",
    "plt.legend(loc=3)\n",
    "plt.savefig('metrics_filter.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
