{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from LoadSplitData import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape (24076, 80, 80, 3), label shape (24076,), ratio of authorized data 0.4503655092208008\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-74581b0d61b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\Users\\dbsnail\\ImageFolder\\pickle'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\dbsnail\\Python\\FaceRecognition\\LoadSplitData.py\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(self, img_rows, img_cols, img_channels, nb_classes, data_path)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[1;31m#reshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mX_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "data = Process()\n",
    "data_path = r'C:\\Users\\dbsnail\\ImageFolder\\pickle'\n",
    "data.split_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "#FILE_PATH = r'C:\\Users\\dbsnail\\ImageProject\\model_with_grid.h5'\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', activation = 'relu', input_shape=dataset.X_train.shape[1:]))\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        #self.model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(48, 3, 3, border_mode='same', activation = 'relu'))\n",
    "    model.add(Convolution2D(48, 3, 3, border_mode='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        #self.model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', activation = 'relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))        \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(960))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', ##'binary_crossentropy'\n",
    "                           optimizer=sgd,\n",
    "                           metrics=['accuracy'])  #['precision']) #   \n",
    "        \n",
    "    return model\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "nb_epochs= [10, 50, 100]\n",
    "model = KerasClassifier(build_fn = create_model, verbose=0)\n",
    "param_grid = dict(batch_size=batch_size, nb_epoch=nb_epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(data.X_train, data.Y_train)\n",
    "        \n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "\"\"\"\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "        \n",
    "\n",
    "\n",
    "        if not data_augmentation:\n",
    "            print('Not using data augmentation.')\n",
    "            self.model.fit(dataset.X_train, dataset.Y_train,\n",
    "                           batch_size=batch_size,\n",
    "                           nb_epoch=nb_epoch,\n",
    "                           validation_split=0.3,\n",
    "                           shuffle=True)\n",
    "        else:\n",
    "            print('Using real-time data augmentation.')\n",
    "\n",
    "            # This will do preprocessing and realtime data augmentation\n",
    "            datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,             # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,              # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,   # divide each input by its std\n",
    "                zca_whitening=False,                  # apply ZCA whitening\n",
    "                rotation_range=0.,                    # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.,                 # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.,                # randomly shift images vertically (fraction of total height)\n",
    "                channel_shift_range=0.2,\n",
    "                fill_mode = 'nearest',        # Points outside the boundaries of the input are filled according to the given mode.\n",
    "                horizontal_flip=False,                 # randomly flip images\n",
    "                vertical_flip=False)                  # randomly flip images\n",
    "\n",
    "            # compute quantities required for featurewise normalization\n",
    "            # (std, mean, and principal components if ZCA whitening is applied)\n",
    "            datagen.fit(dataset.X_train)\n",
    "\n",
    "            # fit the model on the batches generated by datagen.flow()\n",
    "            self.model.fit_generator(datagen.flow(dataset.X_train, dataset.Y_train,\n",
    "                                                  batch_size=batch_size),\n",
    "                                     samples_per_epoch=dataset.X_train.shape[0],\n",
    "                                     nb_epoch=nb_epoch,\n",
    "                                     validation_split=0.3)\n",
    "   \n",
    "    def save(self, file_path=FILE_PATH):\n",
    "        print('Model Saved.')\n",
    "        self.model.save(file_path)\n",
    "\n",
    "    def load(self, file_path=FILE_PATH):\n",
    "        print('Model Loaded.')\n",
    "        self.model = load_model(file_path)\n",
    "\n",
    "    def predict(self, image):\n",
    "        image = image.reshape((1, 80, 80, 3))\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        result = self.model.predict_proba(image)\n",
    "        print(result)\n",
    "        result = self.model.predict_classes(image)\n",
    "\n",
    "        return result[0]\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        score = self.model.evaluate(dataset.X_test, dataset.Y_test, batch_size = batch_size, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (self.model.metrics_names[1], score[1] * 100))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.load()\n",
    "model.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\sample1.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\sample2.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\sample3.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\sample4.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\chendaoming.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\zhourunfa.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\chenbaoguo.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\zhangguoli.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\linyongjian.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\lixuejian.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\wangziwen.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\tangguoqiang.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\dbsnail\\ImageFolder\\test\\zhangyimou.jpg')\n",
    "resized_image = imutils.resize(image, height = 50)\n",
    "model.predict(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
